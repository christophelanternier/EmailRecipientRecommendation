{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nprnd\n",
    "import pandas as pd\n",
    "import heapq\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_data = '../data/'\n",
    "\n",
    "##########################\n",
    "# load files #                           \n",
    "##########################\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "#training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "training_info = pd.read_csv(path_to_data+\"training_info2.csv\",sep=',', header=0, index_col=0)\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "#test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)\n",
    "test_info = pd.read_csv(path_to_data+\"test_info2.csv\",sep=',', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/home/marc/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:13: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "# Correct dates and put datetime format\n",
    "# We do that because we noticed test_set is only composed of email posterior to the ones of train_set. \n",
    "# Datetime format allows to simulate posteriority in our train/test split\n",
    "from datetime import datetime\n",
    "\n",
    "for row in training_info.sort(['date']).iterrows():\n",
    "    date = row[1]['date']\n",
    "    if date[:3] == '000':\n",
    "        date = '2' + date[1:]\n",
    "        \n",
    "    training_info.loc[row[0], 'date'] = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for row in test_info.sort(['date']).iterrows():\n",
    "    date = row[1]['date']\n",
    "        \n",
    "    test_info.loc[row[0], 'date'] = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = True\n",
    "training_info = training_info.sort_values(by='date')\n",
    "\n",
    "# affect a training set and a testing set\n",
    "if submission:\n",
    "   # submission procedure\n",
    "   X_train_info = training_info\n",
    "   X_test_info = test_info\n",
    "   \n",
    "else:\n",
    "   # test procedure\n",
    "   split_date=datetime(2001, 8, 24)\n",
    "   X_train_info = training_info[training_info.date <= split_date]\n",
    "   \n",
    "   #Randomize selection of test set:\n",
    "   X_test_info = training_info[training_info.date > split_date]\n",
    "   mask = nprnd.choice(range(X_test_info.shape[0]), size=1000, replace=False)\n",
    "   X_test_info.index = range(X_test_info.shape[0])\n",
    "   X_test_info = X_test_info[X_test_info.index.isin(mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "# Functions #                           \n",
    "##########################\n",
    "\n",
    "# Check if the name is in the beguinning of the email\n",
    "def header_address_ressemblance(text, address):\n",
    "    head = text[:10].lower()\n",
    "    name = address[:address.index('@')].split('.')\n",
    "    head_bonus = 0.\n",
    "    for i,n in enumerate(name):\n",
    "        if len(n)>1:\n",
    "            if n in head:\n",
    "                head_bonus = 1.0\n",
    "    return head_bonus\n",
    "\n",
    "# Compute score\n",
    "def mean_ap(suggested_10_recipients, ground_truth):\n",
    "    MAP = 0\n",
    "    correct_guess = 0\n",
    "    for i, suggestion in enumerate(suggested_10_recipients):\n",
    "        if suggestion in ground_truth:\n",
    "            correct_guess +=1\n",
    "            MAP += float(correct_guess)/(i+1)\n",
    "    MAP = float(MAP)/min(10, len(ground_truth))\n",
    "    return MAP\n",
    "\n",
    "def most_similar_sklearn(array_embedding_sparse, mail_tfidf):\n",
    "    similarities = cosine_similarity(array_embedding_sparse, mail_tfidf)\n",
    "    closest_ids = similarities[:,0].argsort()[::-1]\n",
    "    return closest_ids, similarities\n",
    "\n",
    "def get_n_closest_emails(sender, nb_neigh, closest_ids, info):\n",
    "    # Get the closest emails WRITTEN BY THE SENDER\n",
    "    closest_ids_of_sender = []\n",
    "    for idx in closest_ids:\n",
    "        sender_wrote_id = sender == info['sender'][idx]\n",
    "        if sender_wrote_id:\n",
    "            closest_ids_of_sender.append(idx)\n",
    "        if len(closest_ids_of_sender) == nb_neigh:\n",
    "            break\n",
    "    return closest_ids_of_sender\n",
    "\n",
    "def get_10_recipients(sender, closest_ids_of_sender, training_info, closest_emails_dates, similarities, mail_header, mail_tfidf):\n",
    "    dic_of_recipients = {}\n",
    "    for idx in closest_ids_of_sender:\n",
    "        recipients = training_info.loc[idx,'recipients'].split()\n",
    "        # Loop over recipients to evaluate their score\n",
    "        for recipient in recipients:\n",
    "            if ('@' in recipient):\n",
    "                head = header_address_ressemblance(mail_header, recipient)\n",
    "                weight = similarities[idx]*closest_emails_dates['weight_date'][idx]/len(closest_ids_of_sender)\n",
    "                if recipient not in dic_of_recipients.keys():\n",
    "                    dic_of_recipients[recipient] = weight\n",
    "                else:\n",
    "                    dic_of_recipients[recipient] += weight\n",
    "    suggested_10_recipients = heapq.nlargest(10, dic_of_recipients, key=dic_of_recipients.get)\n",
    "    \n",
    "    return suggested_10_recipients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute tf-idf for all emails\n",
    "tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "array_embedding_sparse = tfidf.fit_transform(X_train_info['body'].values)\n",
    "\n",
    "#re-arrange train index to have same index as array_embedding_sparse\n",
    "X_train_info.index = range(X_train_info.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of closest neighbors to collect recipients from:\n",
    "nb_neigh = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:07:53.226363\n"
     ]
    }
   ],
   "source": [
    "# Mark down the time\n",
    "t_begin = datetime.now()\n",
    "\n",
    "results = pd.DataFrame(columns=['recipients'])\n",
    "results.index.name = 'mid'\n",
    "\n",
    "all_mean_ap = []\n",
    "all_ground_truth = []\n",
    "all_suggestions = []\n",
    "for query_id in X_test_info.index.values:\n",
    "\n",
    "    mail = X_test_info['body'][query_id]\n",
    "    mail_date = X_test_info['date'][query_id]\n",
    "    query_mid = X_test_info['mid'][query_id]\n",
    "    sender = X_test_info['sender'][query_id]\n",
    "    mail_tfidf= tfidf.transform([mail])\n",
    "    \n",
    "    closest_ids, similarities = most_similar_sklearn(array_embedding_sparse, mail_tfidf)\n",
    "\n",
    "    # find the closest emails (written or received by the sender) to the query one\n",
    "    closest_ids_of_sender = get_n_closest_emails(sender, nb_neigh, closest_ids, X_train_info)\n",
    "    \n",
    "    # sort ids per date\n",
    "    closest_emails_dates = pd.DataFrame(X_train_info['date'][closest_ids_of_sender].sort_values())\n",
    "    closest_emails_dates['weight_date'] = range(1, len(closest_ids_of_sender)+1)\n",
    "\n",
    "    # Create dictionnary of all recipient for the 30 most similar emails, and get frequency\n",
    "    # For the moment it is only the brute frequency, maybe we could refine this by adding wheights according to the closseness of the email\n",
    "    suggested_10_recipients = get_10_recipients(sender, closest_ids_of_sender, X_train_info, closest_emails_dates, similarities,mail[10:], mail_tfidf)\n",
    "\n",
    "    if submission:\n",
    "        string_recipients = ''\n",
    "        for k in suggested_10_recipients:\n",
    "            string_recipients+=k + ' '\n",
    "        results.loc[query_mid, 'recipients'] = string_recipients\n",
    "    else:\n",
    "        ground_truth = X_test_info['recipients'][query_id].split()\n",
    "        all_suggestions.append(suggested_10_recipients)\n",
    "        ground_truth.append(ground_truth)\n",
    "        all_mean_ap.append(mean_ap(suggested_10_recipients, ground_truth))\n",
    "    \n",
    "# Print the run time\n",
    "print datetime.now()-t_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to test your work when submission = False\n",
    "# np.mean(all_mean_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save results\n",
    "results.to_csv('../submission/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

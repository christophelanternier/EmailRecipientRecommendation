{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "import numpy as np\n",
    "import heapq\n",
    "import json\n",
    "import operator\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from stop_words import get_stop_words\n",
    "import json\n",
    "from imblearn.over_sampling import  SMOTE \n",
    "import numpy.random as nprnd\n",
    "\n",
    "\n",
    "stop_words = get_stop_words('english')\n",
    "path_to_data = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "#training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "training_info = pd.read_csv(path_to_data+\"training_info2.csv\",sep=',', header=0, index_col=0)\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "#test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)\n",
    "test_info = pd.read_csv(path_to_data+\"test_info2.csv\",sep=',', header=0, index_col=0)\n",
    "\n",
    "global sent_to\n",
    "with io.open('../data/sent_to.json') as json_data:\n",
    "    sent_to = json.load(json_data)\n",
    "\n",
    "global received_from\n",
    "with io.open('../data/received_from.json') as json_data:\n",
    "    received_from = json.load(json_data)\n",
    "    \n",
    "cut_indexes = {datetime(2001, 6, 24): 428724, \n",
    "               datetime(2001, 7, 24): 927522,\n",
    "               datetime(2001, 8, 24): 1153398}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correct dates and put datetime format\n",
    "# We do that because we noticed test_set is only composed of email posterior to the ones of train_set. \n",
    "# Datetime format allows to simulate posteriority in our train/test split\n",
    "from datetime import datetime\n",
    "\n",
    "for row in training_info.sort_values(by='date').iterrows():\n",
    "    date = row[1]['date']\n",
    "    if date[:3] == '000':\n",
    "        date = '2' + date[1:]\n",
    "        \n",
    "    training_info.loc[row[0], 'date'] = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for row in test_info.sort_values(by='date').iterrows():\n",
    "    date = row[1]['date']\n",
    "        \n",
    "    test_info.loc[row[0], 'date'] = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar_sklearn(array_embedding_sparse, mail_tfidf, n):\n",
    "    \n",
    "    similarities = cosine_similarity(array_embedding_sparse, mail_tfidf)\n",
    "    closest_ids = similarities[:,0].argsort()[::-1]\n",
    "    \n",
    "    return closest_ids[:n], similarities\n",
    "\n",
    "def get_sender(query_mid, training):\n",
    "    for row in training.iterrows():\n",
    "        mids = row[1]['mids'].split()\n",
    "        for mid in mids:\n",
    "            if int(mid) == query_mid:\n",
    "                sender = row[1]['sender']\n",
    "                break\n",
    "    return sender\n",
    "\n",
    "\n",
    "def get_10_recipients(closest_ids_per_sender, training_info, similarities, closest_emails_dates):\n",
    "    dic_of_recipients = {}\n",
    "    dic_recency2 = {}\n",
    "    #weight = len(closest_ids_per_sender)+1\n",
    "    for idx in closest_ids_per_sender:\n",
    "        recipients = training_info.loc[idx,'recipients'].split()\n",
    "        for recipient in recipients:\n",
    "            if '@' in recipient:\n",
    "                dic_of_recipients[recipient] = dic_of_recipients.get(recipient, 0) + similarities[idx][0]\n",
    "                dic_recency2[recipient] = dic_recency2.get(recipient, 0) + closest_emails_dates['weight_date'][idx]\n",
    "    # the max here is a precaution not to divide by zero in the case were no similarity is found (happened with 'this is a testds')\n",
    "\n",
    "    norm = max(sum(dic_of_recipients.values()), 0.0000001)\n",
    "    norm_recency = max(sum(dic_recency2.values()), 0.0000001)\n",
    "    for k,v in dic_of_recipients.iteritems():\n",
    "        dic_of_recipients[k] = float(v)/norm\n",
    "        dic_recency2[k] = float(dic_recency2[k])/norm_recency\n",
    "        \n",
    "    return dic_of_recipients, dic_recency2\n",
    "\n",
    "def get_recency_features(X_train_info_sender, mail_date, n_recency_features):    \n",
    "    dic_recency = {}\n",
    "    df_last_sent_emails = X_train_info_sender[X_train_info_sender.date< mail_date].sort_values(by = 'date', ascending = False)[:n_recency_features]\n",
    "    for row in df_last_sent_emails.iterrows():\n",
    "        recipients = row[1]['recipients'].split()\n",
    "        for recipient in recipients:\n",
    "            if '@' in recipient:\n",
    "                dic_recency[recipient] = dic_recency.get(recipient, 0) + 1\n",
    "    norm = sum(dic_recency.values())\n",
    "    for k,v in dic_recency.iteritems():\n",
    "        dic_recency[k] = float(v)/norm\n",
    "    \n",
    "    return dic_recency\n",
    "\n",
    "def mean_ap(suggested_10_recipients, ground_truth):\n",
    "    MAP = 0\n",
    "    correct_guess = 0\n",
    "    for i, suggestion in enumerate(suggested_10_recipients):\n",
    "        if suggestion in ground_truth:\n",
    "            correct_guess +=1\n",
    "            MAP += float(correct_guess)/(i+1)\n",
    "    MAP = float(MAP)/min(10, len(ground_truth))\n",
    "    return MAP\n",
    "\n",
    "def header_address_ressemblance(text, address):\n",
    "    head = text[:10].lower()\n",
    "    name = address[:address.index('@')].split('.')\n",
    "    for n in name:\n",
    "        if len(n)>2:\n",
    "            if n in head:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def generate_features(X_train_info_sender, mail_tfidf, mail_date, ground_truth, sender, n, mail_header):\n",
    "    \n",
    "    #print X_train_info_sender.shape\n",
    "    index_sender = X_train_info_sender.index.values\n",
    "    X_train_info_sender.index = range(X_train_info_sender.shape[0])\n",
    "    array_embedding_sparse_sender = array_embedding_sparse[index_sender]\n",
    "\n",
    "    closest_ids_per_sender, similarities = most_similar_sklearn(array_embedding_sparse_sender, mail_tfidf, n)\n",
    "    \n",
    "    closest_emails_dates = pd.DataFrame(X_train_info_sender['date'][closest_ids_per_sender].sort_values())\n",
    "    closest_emails_dates['weight_date'] = range(1, len(closest_ids_per_sender)+1)\n",
    "\n",
    "    #dic_recency = get_recency_features(X_train_info_sender, mail_date, n_recency_features)\n",
    "    \n",
    "    dic_of_recipients, dic_recency2 = get_10_recipients(closest_ids_per_sender, X_train_info_sender, similarities, closest_emails_dates)\n",
    "    if mail_header:\n",
    "        new_features_per_mail = np.zeros((len(dic_of_recipients), 5))\n",
    "    else:\n",
    "        new_features_per_mail = np.zeros((len(dic_of_recipients), 4))\n",
    "        \n",
    "    labels_per_mail = np.zeros((len(dic_of_recipients), 1))\n",
    "    index = 0\n",
    "    for k,v in dic_of_recipients.iteritems():\n",
    "        KNNScore = v\n",
    "        NSF = sent_to[sender][k]\n",
    "        NRF = 0\n",
    "        if sender in received_from.keys():\n",
    "            NRF = received_from[sender].get(k, 0)\n",
    "\n",
    "        recency = dic_recency2[k]\n",
    "        \n",
    "        if ground_truth != None:\n",
    "            if k in ground_truth:\n",
    "                labels_per_mail[index, :] = 1\n",
    "        if mail_header:\n",
    "            head = 1.0 * header_address_ressemblance(mail_header, k)\n",
    "            new_features_per_mail[index, :] = [KNNScore, NSF, NRF, recency, head]\n",
    "        else:\n",
    "            new_features_per_mail[index, :] = [KNNScore, NSF, NRF, recency]\n",
    "        index +=1\n",
    "\n",
    "    return new_features_per_mail, labels_per_mail, dic_of_recipients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare train and test\n",
    "training_info = training_info.sort_values(by='date')\n",
    "\n",
    "X_train_info = training_info\n",
    "X_test_info = test_info\n",
    "\n",
    "# compute tf-idf\n",
    "tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "array_embedding_sparse = tfidf.fit_transform(np.concatenate((X_train_info['body'].values,X_test_info['body'].values)))\n",
    "array_embedding_sparse = array_embedding_sparse[:X_train_info.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "100\n",
      "0:00:04.078148\n",
      "ok\n",
      "ok\n",
      "200\n",
      "0:00:06.034047\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "300\n",
      "0:00:05.394363\n",
      "ok\n",
      "ok\n",
      "400\n",
      "0:00:05.388855\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "500\n",
      "0:00:05.181505\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "600\n",
      "0:00:05.641434\n",
      "ok\n",
      "700\n",
      "0:00:05.398228\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "800\n",
      "0:00:05.176346\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "900\n",
      "0:00:04.362564\n",
      "ok\n",
      "1000\n",
      "0:00:05.549238\n",
      "1100\n",
      "0:00:06.435016\n",
      "1200\n",
      "0:00:09.926155\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7fc1079096e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Compute Features For this email\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mnew_features_per_mail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_per_mail\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdic_of_recipients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_info_sender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmail_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmail_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmail\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Add to global features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mnew_features_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_features_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_features_per_mail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6b25197dc754>\u001b[0m in \u001b[0;36mgenerate_features\u001b[0;34m(X_train_info_sender, mail_tfidf, mail_date, ground_truth, sender, n, mail_header)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mNSF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_to\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mNRF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0msender\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreceived_from\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mNRF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreceived_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_features_all = np.zeros((0,5))\n",
    "labels_all = np.zeros((0,1))\n",
    "\n",
    "# number of closest neighbors to collect recipients from (referred as k in report):\n",
    "n = 70\n",
    "\n",
    "#re-arrange train index\n",
    "X_train_info.index = range(X_train_info.shape[0])\n",
    "\n",
    "t_all = datetime.now()\n",
    "t_100 = datetime.now()\n",
    "\n",
    "count = 1\n",
    "\n",
    "for query_id in X_train_info.index.values:\n",
    "    \n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        print count\n",
    "        print datetime.now()-t_100\n",
    "        t_100 = datetime.now()\n",
    "\n",
    "    # Get info on considered mail\n",
    "    mail = X_train_info['body'][query_id]\n",
    "    mail_tfidf = tfidf.transform([mail])\n",
    "    mail_date = X_train_info['date'][query_id]\n",
    "    ground_truth = X_train_info['recipients'][query_id].split()\n",
    "    sender = X_train_info['sender'][query_id]\n",
    "\n",
    "    X_train_info_sender = X_train_info[(X_train_info.sender == sender) & (X_train_info.date<mail_date)]\n",
    "    if X_train_info_sender.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # Compute Features For this email\n",
    "    new_features_per_mail, labels_per_mail, dic_of_recipients = generate_features(X_train_info_sender, mail_tfidf, mail_date, ground_truth, sender, n, mail[:10])\n",
    "    # Add to global features\n",
    "    new_features_all = np.concatenate((new_features_all, new_features_per_mail))\n",
    "    labels_all = np.concatenate((labels_all, labels_per_mail))\n",
    "\n",
    "\n",
    "print \"total took:\", datetime.now()-t_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    np.save('../data/new_features_all_normalized_header_recency_70.npy', new_features_all)\n",
    "    np.save('../data/labels_all_normalized_header_recency_70.npy', labels_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

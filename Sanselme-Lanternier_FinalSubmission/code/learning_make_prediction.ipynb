{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "import numpy as np\n",
    "import heapq\n",
    "import json\n",
    "import operator\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from stop_words import get_stop_words\n",
    "import json\n",
    "from imblearn.over_sampling import  SMOTE \n",
    "import numpy.random as nprnd\n",
    "\n",
    "\n",
    "stop_words = get_stop_words('english')\n",
    "path_to_data = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "#training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "training_info = pd.read_csv(path_to_data+\"training_info2.csv\",sep=',', header=0, index_col=0)\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "#test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)\n",
    "test_info = pd.read_csv(path_to_data+\"test_info2.csv\",sep=',', header=0, index_col=0)\n",
    "\n",
    "global sent_to\n",
    "with io.open('../data/sent_to.json') as json_data:\n",
    "    sent_to = json.load(json_data)\n",
    "\n",
    "global received_from\n",
    "with io.open('../data/received_from.json') as json_data:\n",
    "    received_from = json.load(json_data)\n",
    "    \n",
    "cut_indexes = {datetime(2001, 6, 24): 428724, \n",
    "               datetime(2001, 7, 24): 927522,\n",
    "               datetime(2001, 8, 24): 1153398}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correct dates and put datetime format\n",
    "# We do that because we noticed test_set is only composed of email posterior to the ones of train_set. \n",
    "# Datetime format allows to simulate posteriority in our train/test split\n",
    "from datetime import datetime\n",
    "\n",
    "for row in training_info.sort_values(by='date').iterrows():\n",
    "    date = row[1]['date']\n",
    "    if date[:3] == '000':\n",
    "        date = '2' + date[1:]\n",
    "        \n",
    "    training_info.loc[row[0], 'date'] = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for row in test_info.sort_values(by='date').iterrows():\n",
    "    date = row[1]['date']\n",
    "        \n",
    "    test_info.loc[row[0], 'date'] = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar_sklearn(array_embedding_sparse, mail_tfidf, n):\n",
    "    \n",
    "    similarities = cosine_similarity(array_embedding_sparse, mail_tfidf)\n",
    "    closest_ids = similarities[:,0].argsort()[::-1]\n",
    "    \n",
    "    return closest_ids[:n], similarities\n",
    "\n",
    "def get_sender(query_mid, training):\n",
    "    for row in training.iterrows():\n",
    "        mids = row[1]['mids'].split()\n",
    "        for mid in mids:\n",
    "            if int(mid) == query_mid:\n",
    "                sender = row[1]['sender']\n",
    "                break\n",
    "    return sender\n",
    "\n",
    "\n",
    "def get_10_recipients(closest_ids_per_sender, training_info, similarities, closest_emails_dates):\n",
    "    dic_of_recipients = {}\n",
    "    dic_recency2 = {}\n",
    "    #weight = len(closest_ids_per_sender)+1\n",
    "    for idx in closest_ids_per_sender:\n",
    "        recipients = training_info.loc[idx,'recipients'].split()\n",
    "        for recipient in recipients:\n",
    "            if '@' in recipient:\n",
    "                dic_of_recipients[recipient] = dic_of_recipients.get(recipient, 0) + similarities[idx][0]\n",
    "                dic_recency2[recipient] = dic_recency2.get(recipient, 0) + closest_emails_dates['weight_date'][idx]\n",
    "    # the max here is a precaution not to divide by zero in the case were no similarity is found (happened with 'this is a testds')\n",
    "\n",
    "    norm = max(sum(dic_of_recipients.values()), 0.0000001)\n",
    "    norm_recency = max(sum(dic_recency2.values()), 0.0000001)\n",
    "    for k,v in dic_of_recipients.iteritems():\n",
    "        dic_of_recipients[k] = float(v)/norm\n",
    "        dic_recency2[k] = float(dic_recency2[k])/norm_recency\n",
    "        \n",
    "    return dic_of_recipients, dic_recency2\n",
    "\n",
    "def get_recency_features(X_train_info_sender, mail_date, n_recency_features):    \n",
    "    dic_recency = {}\n",
    "    df_last_sent_emails = X_train_info_sender[X_train_info_sender.date< mail_date].sort_values(by = 'date', ascending = False)[:n_recency_features]\n",
    "    for row in df_last_sent_emails.iterrows():\n",
    "        recipients = row[1]['recipients'].split()\n",
    "        for recipient in recipients:\n",
    "            if '@' in recipient:\n",
    "                dic_recency[recipient] = dic_recency.get(recipient, 0) + 1\n",
    "    norm = sum(dic_recency.values())\n",
    "    for k,v in dic_recency.iteritems():\n",
    "        dic_recency[k] = float(v)/norm\n",
    "    \n",
    "    return dic_recency\n",
    "\n",
    "def mean_ap(suggested_10_recipients, ground_truth):\n",
    "    MAP = 0\n",
    "    correct_guess = 0\n",
    "    for i, suggestion in enumerate(suggested_10_recipients):\n",
    "        if suggestion in ground_truth:\n",
    "            correct_guess +=1\n",
    "            MAP += float(correct_guess)/(i+1)\n",
    "    MAP = float(MAP)/min(10, len(ground_truth))\n",
    "    return MAP\n",
    "\n",
    "def header_address_ressemblance(text, address):\n",
    "    head = text[:10].lower()\n",
    "    name = address[:address.index('@')].split('.')\n",
    "    for n in name:\n",
    "        if len(n)>2:\n",
    "            if n in head:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def generate_features(X_train_info_sender, mail_tfidf, mail_date, ground_truth, sender, n, mail_header):\n",
    "    \n",
    "    #print X_train_info_sender.shape\n",
    "    index_sender = X_train_info_sender.index.values\n",
    "    X_train_info_sender.index = range(X_train_info_sender.shape[0])\n",
    "    array_embedding_sparse_sender = array_embedding_sparse[index_sender]\n",
    "\n",
    "    closest_ids_per_sender, similarities = most_similar_sklearn(array_embedding_sparse_sender, mail_tfidf, n)\n",
    "    \n",
    "    closest_emails_dates = pd.DataFrame(X_train_info_sender['date'][closest_ids_per_sender].sort_values())\n",
    "    closest_emails_dates['weight_date'] = range(1, len(closest_ids_per_sender)+1)\n",
    "\n",
    "    #dic_recency = get_recency_features(X_train_info_sender, mail_date, n_recency_features)\n",
    "    \n",
    "    dic_of_recipients, dic_recency2 = get_10_recipients(closest_ids_per_sender, X_train_info_sender, similarities, closest_emails_dates)\n",
    "    if mail_header:\n",
    "        new_features_per_mail = np.zeros((len(dic_of_recipients), 5))\n",
    "    else:\n",
    "        new_features_per_mail = np.zeros((len(dic_of_recipients), 4))\n",
    "        \n",
    "    labels_per_mail = np.zeros((len(dic_of_recipients), 1))\n",
    "    index = 0\n",
    "    for k,v in dic_of_recipients.iteritems():\n",
    "        KNNScore = v\n",
    "        NSF = sent_to[sender][k]\n",
    "        NRF = 0\n",
    "        if sender in received_from.keys():\n",
    "            NRF = received_from[sender].get(k, 0)\n",
    "\n",
    "        recency = dic_recency2[k]\n",
    "        \n",
    "        if ground_truth != None:\n",
    "            if k in ground_truth:\n",
    "                labels_per_mail[index, :] = 1\n",
    "        if mail_header:\n",
    "            head = 1.0 * header_address_ressemblance(mail_header, k)\n",
    "            new_features_per_mail[index, :] = [KNNScore, NSF, NRF, recency, head]\n",
    "        else:\n",
    "            new_features_per_mail[index, :] = [KNNScore, NSF, NRF, recency]\n",
    "        index +=1\n",
    "\n",
    "    return new_features_per_mail, labels_per_mail, dic_of_recipients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declare Global variables:\n",
    "global X_train_info\n",
    "global X_test_info\n",
    "global array_embedding_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Choose here to prepare .csv for submission or to test a model locally\n",
    "submission = True\n",
    "training_info = training_info.sort_values(by='date')\n",
    "\n",
    "if submission:\n",
    "    # submission procedure\n",
    "    X_train_info = training_info\n",
    "    X_test_info = test_info\n",
    "    \n",
    "else:\n",
    "    # test procedure\n",
    "    split_date=datetime(2001, 8, 24)\n",
    "    X_train_info = training_info[training_info.date <= split_date]\n",
    "    \n",
    "    #Randomize selection of test set:\n",
    "    X_test_info = training_info[training_info.date > split_date]\n",
    "    mask = nprnd.choice(range(X_test_info.shape[0]), size=1000, replace=False)\n",
    "    X_test_info.index = range(X_test_info.shape[0])\n",
    "    X_test_info = X_test_info[X_test_info.index.isin(mask)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if submission:\n",
    "    tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "    array_embedding_sparse = tfidf.fit_transform(np.concatenate((X_train_info['body'].values,X_test_info['body'].values)))\n",
    "    array_embedding_sparse = array_embedding_sparse[:X_train_info.shape[0]]\n",
    "else:\n",
    "    tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "    array_embedding_sparse = tfidf.fit_transform(X_train_info['body'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previously loaded features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features_all = np.load('../data/new_features_all_normalized_header_recency_70.npy')\n",
    "labels_all = np.ravel(np.load('../data/labels_all_normalized_header_recency_70.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Without NRF feature:\n",
    "new_features_all = new_features_all[:, [0,1,3,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:05.407634\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "\n",
    "_classifier = 'LR'\n",
    "\n",
    "if _classifier == 'LinearSVM':\n",
    "    \n",
    "    SVM = LinearSVC(dual=False, class_weight='balanced', C=0.001)\n",
    "    if submission == False:\n",
    "        SVM.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        SVM.fit(new_features_all, labels_all)\n",
    "    classifier = SVM\n",
    "elif _classifier == 'LR':\n",
    "    \n",
    "    LR = LogisticRegression()\n",
    "    if submission == False:\n",
    "        LR.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        LR.fit(new_features_all, labels_all)\n",
    "    classifier = LR\n",
    "\n",
    "elif _classifier == 'ABC':\n",
    "    ABC = AdaBoostClassifier()\n",
    "    if submission == False:\n",
    "        ABC.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        ABC.fit(new_features_all, labels_all)\n",
    "    classifier = ABC\n",
    "\n",
    "elif _classifier == 'RFC':\n",
    "    RFC = RandomForestClassifier(n_estimators=50, class_weight='balanced')\n",
    "    if submission == False:\n",
    "        RFC.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        RFC.fit(new_features_all, labels_all)\n",
    "    classifier = RFC\n",
    "\n",
    "elif _classifier == 'SVM':\n",
    "    SVM = SVC(kernel='rbf')\n",
    "    if submission == False:\n",
    "        SVM.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        SVM.fit(new_features_all, labels_all)\n",
    "\n",
    "\n",
    "print datetime.now() - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test features and make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0:00:06.906880\n",
      "200\n",
      "0:00:06.522230\n",
      "300\n",
      "0:00:08.387563\n",
      "400\n",
      "0:00:08.417231\n",
      "500\n",
      "0:00:05.935544\n",
      "600\n",
      "0:00:06.647194\n",
      "700\n",
      "0:00:07.259435\n",
      "800\n",
      "0:00:08.008669\n",
      "900\n",
      "0:00:05.441563\n",
      "1000\n",
      "0:00:05.883587\n",
      "1100\n",
      "0:00:06.794425\n",
      "1200\n",
      "0:00:10.435439\n",
      "1300\n",
      "0:00:08.222660\n",
      "1400\n",
      "0:00:08.049165\n",
      "1500\n",
      "0:00:07.437767\n",
      "1600\n",
      "0:00:08.479812\n",
      "1700\n",
      "0:00:07.787986\n",
      "1800\n",
      "0:00:05.868738\n",
      "1900\n",
      "0:00:06.720847\n",
      "2000\n",
      "0:00:05.915670\n",
      "2100\n",
      "0:00:08.075077\n",
      "2200\n",
      "0:00:07.751514\n",
      "2300\n",
      "0:00:08.676471\n",
      "total took: 0:02:57.611761\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 30\n",
    "\n",
    "#re-arrange train index\n",
    "X_train_info.index = range(X_train_info.shape[0])\n",
    "t_all = datetime.now()\n",
    "t_100 = datetime.now()\n",
    "results = pd.DataFrame(columns=['recipients'])\n",
    "results.index.name = 'mid'\n",
    "all_mean_ap = []\n",
    "all_ground_truth = []\n",
    "all_suggestions = []\n",
    "\n",
    "count=0\n",
    "for query_id in X_test_info.index.values:\n",
    "\n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        print count\n",
    "        print datetime.now()-t_100\n",
    "        t_100 = datetime.now()\n",
    "\n",
    "    mail = X_test_info['body'][query_id]\n",
    "    mail_tfidf = tfidf.transform([mail])\n",
    "    mail_date = X_test_info['date'][query_id]\n",
    "    if submission:\n",
    "        ground_truth = None\n",
    "        query_mid = X_test_info['mid'][query_id]\n",
    "    else:\n",
    "        ground_truth = X_test_info['recipients'][query_id].split()\n",
    "    sender = X_test_info['sender'][query_id]\n",
    "\n",
    "    X_train_info_sender = X_train_info[(X_train_info.sender == sender) & (X_train_info.date<mail_date)]\n",
    "    if X_train_info_sender.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # Compute Features For this email\n",
    "    new_features_per_mail, labels_per_mail, dic_of_recipients = generate_features(X_train_info_sender, mail_tfidf, mail_date, ground_truth, sender, n, mail[:10])\n",
    "    # Once the features are computed, we can predict the 10 recipients\n",
    "    if _classifier == 'LinearSVM':\n",
    "        order = classifier.decision_function(new_features_per_mail).argsort()[::-1]\n",
    "    else:\n",
    "        order = classifier.predict_proba(new_features_per_mail[:, [0,1,3,4]])[:,1].argsort()[::-1]\n",
    "    recipients = np.array(dic_of_recipients.keys())\n",
    "    suggested_10_recipients = recipients[order][:10]\n",
    "\n",
    "    if submission:\n",
    "        string_recipients = ''\n",
    "        for k in suggested_10_recipients:\n",
    "            string_recipients+=k + ' '\n",
    "        results.loc[query_mid, 'recipients'] = string_recipients\n",
    "    else:\n",
    "\n",
    "        all_suggestions.append(suggested_10_recipients)\n",
    "        all_ground_truth.append(ground_truth)\n",
    "        all_mean_ap.append(mean_ap(suggested_10_recipients, ground_truth))\n",
    "\n",
    "print \"total took:\", datetime.now()-t_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save as .csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv('../submission/learning_basic_LR_with_new_features_without_NRF_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

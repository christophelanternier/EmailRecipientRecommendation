{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "import numpy as np\n",
    "import heapq\n",
    "import json\n",
    "import operator\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from stop_words import get_stop_words\n",
    "import json\n",
    "\n",
    "from imblearn.over_sampling import  SMOTE \n",
    "\n",
    "import numpy.random as nprnd\n",
    "\n",
    "stop_words = get_stop_words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_data = '../data/'\n",
    "\n",
    "##########################\n",
    "# load files #                           \n",
    "##########################\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "#training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "training_info = pd.read_csv(path_to_data+\"training_info2.csv\",sep=',', header=0, index_col=0)\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "#test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)\n",
    "test_info = pd.read_csv(path_to_data+\"test_info2.csv\",sep=',', header=0, index_col=0)\n",
    "\n",
    "global sent_to\n",
    "with io.open('../data/sent_to.json') as json_data:\n",
    "    sent_to = json.load(json_data)\n",
    "\n",
    "global received_from\n",
    "with io.open('../data/received_from.json') as json_data:\n",
    "    received_from = json.load(json_data)\n",
    "    \n",
    "cut_indexes = {datetime(2001, 6, 24): 428724, \n",
    "               datetime(2001, 7, 24): 927522,\n",
    "               datetime(2001, 8, 24): 1153398}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophelanternier/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "/Users/christophelanternier/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:13: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "# Correct dates and put datetime format\n",
    "# We do that because we noticed test_set is only composed of email posterior to the ones of train_set. \n",
    "# Datetime format allows to simulate posteriority in our train/test split\n",
    "from datetime import datetime\n",
    "\n",
    "for row in training_info.sort(['date']).iterrows():\n",
    "    date = row[1]['date']\n",
    "    if date[:3] == '000':\n",
    "        date = '2' + date[1:]\n",
    "        \n",
    "    training_info.loc[row[0], 'date'] = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "for row in test_info.sort(['date']).iterrows():\n",
    "    date = row[1]['date']\n",
    "        \n",
    "    test_info.loc[row[0], 'date'] = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar_sklearn(array_embedding_sparse, mail_tfidf, n):\n",
    "    \n",
    "    similarities = cosine_similarity(array_embedding_sparse, mail_tfidf)\n",
    "    closest_ids = similarities[:,0].argsort()[::-1]\n",
    "    \n",
    "    return closest_ids[:n], similarities\n",
    "\n",
    "def get_sender(query_mid, training):\n",
    "    for row in training.iterrows():\n",
    "        mids = row[1]['mids'].split()\n",
    "        for mid in mids:\n",
    "            if int(mid) == query_mid:\n",
    "                sender = row[1]['sender']\n",
    "                break\n",
    "    return sender\n",
    "\n",
    "\n",
    "def get_10_recipients(closest_ids_per_sender, training_info, similarities, closest_emails_dates):\n",
    "    dic_of_recipients = {}\n",
    "    dic_recency2 = {}\n",
    "    #weight = len(closest_ids_per_sender)+1\n",
    "    for idx in closest_ids_per_sender:\n",
    "        recipients = training_info.loc[idx,'recipients'].split()\n",
    "        for recipient in recipients:\n",
    "            if '@' in recipient:\n",
    "                dic_of_recipients[recipient] = dic_of_recipients.get(recipient, 0) + similarities[idx][0]\n",
    "                dic_recency2[recipient] = dic_recency2.get(recipient, 0) + closest_emails_dates['weight_date'][idx]\n",
    "    # the max here is a precaution not to divide by zero in the case were no similarity is found (happened with 'this is a testds')\n",
    "\n",
    "    norm = max(sum(dic_of_recipients.values()), 0.0000001)\n",
    "    norm_recency = max(sum(dic_recency2.values()), 0.0000001)\n",
    "    for k,v in dic_of_recipients.iteritems():\n",
    "        dic_of_recipients[k] = float(v)/norm\n",
    "        dic_recency2[k] = float(dic_recency2[k])/norm_recency\n",
    "        \n",
    "    return dic_of_recipients, dic_recency2\n",
    "\n",
    "def get_recency_features(X_train_info_sender, mail_date, n_recency_features):    \n",
    "    dic_recency = {}\n",
    "    df_last_sent_emails = X_train_info_sender[X_train_info_sender.date< mail_date].sort_values(by = 'date', ascending = False)[:n_recency_features]\n",
    "    for row in df_last_sent_emails.iterrows():\n",
    "        recipients = row[1]['recipients'].split()\n",
    "        for recipient in recipients:\n",
    "            if '@' in recipient:\n",
    "                dic_recency[recipient] = dic_recency.get(recipient, 0) + 1\n",
    "    norm = sum(dic_recency.values())\n",
    "    for k,v in dic_recency.iteritems():\n",
    "        dic_recency[k] = float(v)/norm\n",
    "    \n",
    "    return dic_recency\n",
    "\n",
    "def mean_ap(suggested_10_recipients, ground_truth):\n",
    "    MAP = 0\n",
    "    correct_guess = 0\n",
    "    for i, suggestion in enumerate(suggested_10_recipients):\n",
    "        if suggestion in ground_truth:\n",
    "            correct_guess +=1\n",
    "            MAP += float(correct_guess)/(i+1)\n",
    "    MAP = float(MAP)/min(10, len(ground_truth))\n",
    "    return MAP\n",
    "\n",
    "def header_address_ressemblance(text, address):\n",
    "    head = text[:10].lower()\n",
    "    name = address[:address.index('@')].split('.')\n",
    "    for n in name:\n",
    "        if len(n)>2:\n",
    "            if n in head:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def generate_features(X_train_info_sender, mail_tfidf, mail_date, ground_truth, sender, n, mail_header):\n",
    "    \n",
    "    #print X_train_info_sender.shape\n",
    "    index_sender = X_train_info_sender.index.values\n",
    "    X_train_info_sender.index = range(X_train_info_sender.shape[0])\n",
    "    array_embedding_sparse_sender = array_embedding_sparse[index_sender]\n",
    "\n",
    "    closest_ids_per_sender, similarities = most_similar_sklearn(array_embedding_sparse_sender, mail_tfidf, n)\n",
    "    \n",
    "    closest_emails_dates = pd.DataFrame(X_train_info_sender['date'][closest_ids_per_sender].sort_values())\n",
    "    closest_emails_dates['weight_date'] = range(1, len(closest_ids_per_sender)+1)\n",
    "\n",
    "    #dic_recency = get_recency_features(X_train_info_sender, mail_date, n_recency_features)\n",
    "    \n",
    "    dic_of_recipients, dic_recency2 = get_10_recipients(closest_ids_per_sender, X_train_info_sender, similarities, closest_emails_dates)\n",
    "    if mail_header:\n",
    "        new_features_per_mail = np.zeros((len(dic_of_recipients), 5))\n",
    "    else:\n",
    "        new_features_per_mail = np.zeros((len(dic_of_recipients), 4))\n",
    "        \n",
    "    labels_per_mail = np.zeros((len(dic_of_recipients), 1))\n",
    "    index = 0\n",
    "    for k,v in dic_of_recipients.iteritems():\n",
    "        KNNScore = v\n",
    "        NSF = sent_to[sender][k]\n",
    "        NRF = 0\n",
    "        if sender in received_from.keys():\n",
    "            NRF = received_from[sender].get(k, 0)\n",
    "\n",
    "        recency = dic_recency2[k]\n",
    "        \n",
    "        if ground_truth != None:\n",
    "            if k in ground_truth:\n",
    "                labels_per_mail[index, :] = 1\n",
    "        if mail_header:\n",
    "            head = 1.0 * header_address_ressemblance(mail_header, k)\n",
    "            new_features_per_mail[index, :] = [KNNScore, NSF, NRF, recency, head]\n",
    "        else:\n",
    "            new_features_per_mail[index, :] = [KNNScore, NSF, NRF, recency]\n",
    "        index +=1\n",
    "\n",
    "    return new_features_per_mail, labels_per_mail, dic_of_recipients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declare Global variables:\n",
    "global X_train_info\n",
    "global X_test_info\n",
    "global array_embedding_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = True\n",
    "training_info = training_info.sort_values(by='date')\n",
    "#test_info = test_info.sort_values(by='date')\n",
    "\n",
    "if submission:\n",
    "    # submission procedure\n",
    "    X_train_info = training_info\n",
    "    X_test_info = test_info\n",
    "    \n",
    "else:\n",
    "    # test procedure\n",
    "    split_date=datetime(2001, 8, 24)\n",
    "    X_train_info = training_info[training_info.date <= split_date]\n",
    "    \n",
    "    #Randomize selection of test set:\n",
    "    X_test_info = training_info[training_info.date > split_date]\n",
    "    mask = nprnd.choice(range(X_test_info.shape[0]), size=1000, replace=False)\n",
    "    X_test_info.index = range(X_test_info.shape[0])\n",
    "    X_test_info = X_test_info[X_test_info.index.isin(mask)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if submission:\n",
    "    tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "    array_embedding_sparse = tfidf.fit_transform(np.concatenate((X_train_info['body'].values,X_test_info['body'].values)))\n",
    "    array_embedding_sparse = array_embedding_sparse[:X_train_info.shape[0]]\n",
    "else:\n",
    "    #With porter stemming:\n",
    "    #tfidf = TfidfVectorizer(tokenizer= tokenize, stop_words = stop_words)\n",
    "    #Without stemming:\n",
    "    tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "    array_embedding_sparse = tfidf.fit_transform(X_train_info['body'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute New features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "100\n",
      "0:00:03.901584\n",
      "ok\n",
      "ok\n",
      "200\n",
      "0:00:05.754569\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "300\n",
      "0:00:05.818732\n",
      "ok\n",
      "ok\n",
      "400\n",
      "0:00:05.328908\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "500\n",
      "0:00:05.486705\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "600\n",
      "0:00:06.060498\n",
      "ok\n",
      "700\n",
      "0:00:05.628680\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "800\n",
      "0:00:05.543324\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "900\n",
      "0:00:04.390703\n",
      "ok\n",
      "1000\n",
      "0:00:05.592563\n",
      "1100\n",
      "0:00:05.654223\n",
      "1200\n",
      "0:00:08.413615\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "1300\n",
      "0:00:06.894669\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "1400\n",
      "0:00:07.423568\n",
      "1500\n",
      "0:00:07.322602\n",
      "1600\n",
      "0:00:08.242883\n",
      "ok\n",
      "ok\n",
      "1700\n",
      "0:00:06.322734\n",
      "ok\n",
      "1800\n",
      "0:00:09.399998\n",
      "ok\n",
      "1900\n",
      "0:00:07.124258\n",
      "ok\n",
      "2000\n",
      "0:00:06.712765\n",
      "2100\n",
      "0:00:08.047741\n",
      "2200\n",
      "0:00:07.418757\n",
      "ok\n",
      "2300\n",
      "0:00:06.349716\n",
      "ok\n",
      "2400\n",
      "0:00:07.291204\n",
      "ok\n",
      "2500\n",
      "0:00:08.179981\n",
      "2600\n",
      "0:00:06.615492\n",
      "2700\n",
      "0:00:07.421560\n",
      "ok\n",
      "2800\n",
      "0:00:06.362034\n",
      "2900\n",
      "0:00:06.944750\n",
      "ok\n",
      "ok\n",
      "3000\n",
      "0:00:06.437831\n",
      "3100\n",
      "0:00:06.891153\n",
      "3200\n",
      "0:00:06.607218\n",
      "3300\n",
      "0:00:06.954263\n",
      "3400\n",
      "0:00:07.419916\n",
      "ok\n",
      "3500\n",
      "0:00:06.481160\n",
      "3600\n",
      "0:00:06.405624\n",
      "3700\n",
      "0:00:06.537539\n",
      "ok\n",
      "3800\n",
      "0:00:07.722560\n",
      "3900\n",
      "0:00:07.112431\n",
      "ok\n",
      "4000\n",
      "0:00:08.385203\n",
      "4100\n",
      "0:00:07.077872\n",
      "4200\n",
      "0:00:07.015943\n",
      "ok\n",
      "ok\n",
      "4300\n",
      "0:00:06.917503\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "4400\n",
      "0:00:06.450958\n",
      "ok\n",
      "4500\n",
      "0:00:07.336618\n",
      "4600\n",
      "0:00:06.643936\n",
      "ok\n",
      "4700\n",
      "0:00:06.818605\n",
      "ok\n",
      "4800\n",
      "0:00:06.976216\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "4900\n",
      "0:00:06.539743\n",
      "ok\n",
      "5000\n",
      "0:00:06.675824\n",
      "5100\n",
      "0:00:07.118683\n",
      "ok\n",
      "5200\n",
      "0:00:06.812393\n",
      "5300\n",
      "0:00:07.359386\n",
      "5400\n",
      "0:00:06.629895\n",
      "5500\n",
      "0:00:07.629064\n",
      "5600\n",
      "0:00:07.041788\n",
      "5700\n",
      "0:00:07.309076\n",
      "ok\n",
      "5800\n",
      "0:00:07.979867\n",
      "5900\n",
      "0:00:06.830572\n",
      "ok\n",
      "ok\n",
      "6000\n",
      "0:00:06.633959\n",
      "ok\n",
      "6100\n",
      "0:00:06.682313\n",
      "ok\n",
      "ok\n",
      "6200\n",
      "0:00:08.217428\n",
      "6300\n",
      "0:00:09.314688\n",
      "ok\n",
      "6400\n",
      "0:00:07.964047\n",
      "ok\n",
      "ok\n",
      "6500\n",
      "0:00:07.287421\n",
      "6600\n",
      "0:00:07.081973\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "6700\n",
      "0:00:06.946961\n",
      "ok\n",
      "ok\n",
      "6800\n",
      "0:00:08.089747\n",
      "6900\n",
      "0:00:06.521898\n",
      "ok\n",
      "ok\n",
      "7000\n",
      "0:00:08.334876\n",
      "7100\n",
      "0:00:08.241973\n",
      "ok\n",
      "ok\n",
      "7200\n",
      "0:00:06.694332\n",
      "7300\n",
      "0:00:07.461085\n",
      "ok\n",
      "ok\n",
      "7400\n",
      "0:00:07.400720\n",
      "7500\n",
      "0:00:08.598103\n",
      "ok\n",
      "ok\n",
      "7600\n",
      "0:00:07.068186\n",
      "ok\n",
      "7700\n",
      "0:00:09.013111\n",
      "7800\n",
      "0:00:07.457836\n",
      "7900\n",
      "0:00:08.780591\n",
      "8000\n",
      "0:00:07.353394\n",
      "8100\n",
      "0:00:08.344224\n",
      "8200\n",
      "0:00:08.384560\n",
      "8300\n",
      "0:00:08.932108\n",
      "8400\n",
      "0:00:07.550699\n",
      "ok\n",
      "8500\n",
      "0:00:08.098353\n",
      "8600\n",
      "0:00:07.136919\n",
      "ok\n",
      "ok\n",
      "8700\n",
      "0:00:07.735771\n",
      "8800\n",
      "0:00:08.371057\n",
      "8900\n",
      "0:00:08.284987\n",
      "9000\n",
      "0:00:08.180041\n",
      "9100\n",
      "0:00:07.758492\n",
      "9200\n",
      "0:00:08.504202\n",
      "9300\n",
      "0:00:07.996914\n",
      "9400\n",
      "0:00:08.459563\n",
      "9500\n",
      "0:00:07.701659\n",
      "9600\n",
      "0:00:08.901828\n",
      "9700\n",
      "0:00:08.219120\n",
      "ok\n",
      "9800\n",
      "0:00:08.925034\n",
      "ok\n",
      "9900\n",
      "0:00:07.751809\n",
      "10000\n",
      "0:00:09.022628\n",
      "10100\n",
      "0:00:08.200023\n",
      "ok\n",
      "10200\n",
      "0:00:08.625696\n",
      "ok\n",
      "10300\n",
      "0:00:09.365107\n",
      "10400\n",
      "0:00:08.542619\n",
      "10500\n",
      "0:00:08.490477\n",
      "10600\n",
      "0:00:08.640968\n",
      "10700\n",
      "0:00:10.986675\n",
      "10800\n",
      "0:00:09.114763\n",
      "10900\n",
      "0:00:08.019090\n",
      "11000\n",
      "0:00:08.583731\n",
      "11100\n",
      "0:00:08.380370\n",
      "ok\n",
      "11200\n",
      "0:00:09.972443\n",
      "11300\n",
      "0:00:09.690254\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "11400\n",
      "0:00:08.965307\n",
      "11500\n",
      "0:00:08.862423\n",
      "11600\n",
      "0:00:09.883457\n",
      "ok\n",
      "11700\n",
      "0:00:08.760269\n",
      "ok\n",
      "11800\n",
      "0:00:08.558083\n",
      "11900\n",
      "0:00:08.142968\n",
      "12000\n",
      "0:00:08.950252\n",
      "12100\n",
      "0:00:09.751819\n",
      "ok\n",
      "12200\n",
      "0:00:09.560142\n",
      "ok\n",
      "12300\n",
      "0:00:08.831144\n",
      "12400\n",
      "0:00:10.147536\n",
      "12500\n",
      "0:00:09.875111\n",
      "12600\n",
      "0:00:08.848683\n",
      "12700\n",
      "0:00:10.019540\n",
      "ok\n",
      "12800\n",
      "0:00:09.354739\n",
      "12900\n",
      "0:00:09.694928\n",
      "13000\n",
      "0:00:11.034467\n",
      "ok\n",
      "13100\n",
      "0:00:09.936290\n",
      "13200\n",
      "0:00:10.642177\n",
      "13300\n",
      "0:00:08.940186\n",
      "13400\n",
      "0:00:09.840370\n",
      "13500\n",
      "0:00:10.781844\n",
      "13600\n",
      "0:00:09.941582\n",
      "13700\n",
      "0:00:10.117724\n",
      "ok\n",
      "ok\n",
      "13800\n",
      "0:00:09.823718\n",
      "13900\n",
      "0:00:09.852715\n",
      "ok\n",
      "ok\n",
      "14000\n",
      "0:00:11.646927\n",
      "ok\n",
      "ok\n",
      "14100\n",
      "0:00:11.030551\n",
      "14200\n",
      "0:00:11.516037\n",
      "ok\n",
      "14300\n",
      "0:00:10.294071\n",
      "14400\n",
      "0:00:10.613123\n",
      "14500\n",
      "0:00:11.184710\n",
      "14600\n",
      "0:00:11.244453\n",
      "14700\n",
      "0:00:10.285444\n",
      "14800\n",
      "0:00:10.514106\n",
      "14900\n",
      "0:00:10.423595\n",
      "15000\n",
      "0:00:10.450857\n",
      "15100\n",
      "0:00:10.958064\n",
      "15200\n",
      "0:00:09.682849\n",
      "15300\n",
      "0:00:10.191965\n",
      "ok\n",
      "15400\n",
      "0:00:11.281281\n",
      "15500\n",
      "0:00:10.030106\n",
      "15600\n",
      "0:00:11.142397\n",
      "15700\n",
      "0:00:12.086032\n",
      "15800\n",
      "0:00:11.561027\n",
      "ok\n",
      "15900\n",
      "0:00:09.982550\n",
      "16000\n",
      "0:00:10.883716\n",
      "16100\n",
      "0:00:10.924857\n",
      "ok\n",
      "ok\n",
      "16200\n",
      "0:00:10.420195\n",
      "16300\n",
      "0:00:11.699717\n",
      "16400\n",
      "0:00:12.843764\n",
      "16500\n",
      "0:00:11.566176\n",
      "16600\n",
      "0:00:10.607302\n",
      "16700\n",
      "0:00:11.123552\n",
      "16800\n",
      "0:00:11.551116\n",
      "16900\n",
      "0:00:12.319672\n",
      "17000\n",
      "0:00:10.721448\n",
      "17100\n",
      "0:00:10.378867\n",
      "17200\n",
      "0:00:11.524201\n",
      "17300\n",
      "0:00:10.531068\n",
      "17400\n",
      "0:00:10.308427\n",
      "17500\n",
      "0:00:09.871403\n",
      "17600\n",
      "0:00:10.441261\n",
      "ok\n",
      "17700\n",
      "0:00:12.048670\n",
      "17800\n",
      "0:00:14.714424\n",
      "17900\n",
      "0:00:14.497178\n",
      "18000\n",
      "0:00:11.830416\n",
      "18100\n",
      "0:00:11.965931\n",
      "18200\n",
      "0:00:12.386795\n",
      "18300\n",
      "0:00:12.552115\n",
      "ok\n",
      "18400\n",
      "0:00:11.582695\n",
      "18500\n",
      "0:00:12.017278\n",
      "ok\n",
      "18600\n",
      "0:00:11.678635\n",
      "18700\n",
      "0:00:10.835195\n",
      "18800\n",
      "0:00:10.153543\n",
      "18900\n",
      "0:00:11.423228\n",
      "19000\n",
      "0:00:12.387299\n",
      "ok\n",
      "19100\n",
      "0:00:12.451804\n",
      "19200\n",
      "0:00:14.146504\n",
      "19300\n",
      "0:00:12.559163\n",
      "19400\n",
      "0:00:11.597166\n",
      "19500\n",
      "0:00:12.933578\n",
      "19600\n",
      "0:00:12.427335\n",
      "19700\n",
      "0:00:10.658934\n",
      "19800\n",
      "0:00:08.818272\n",
      "19900\n",
      "0:00:13.708004\n",
      "20000\n",
      "0:00:10.208374\n",
      "20100\n",
      "0:00:11.701962\n",
      "20200\n",
      "0:00:12.036690\n",
      "20300\n",
      "0:00:10.152266\n",
      "ok\n",
      "20400\n",
      "0:00:11.958010\n",
      "20500\n",
      "0:00:12.197937\n",
      "20600\n",
      "0:00:11.074889\n",
      "20700\n",
      "0:00:12.841497\n",
      "20800\n",
      "0:00:12.006504\n",
      "20900\n",
      "0:00:10.376998\n",
      "21000\n",
      "0:00:12.691359\n",
      "21100\n",
      "0:00:14.480682\n",
      "ok\n",
      "21200\n",
      "0:00:12.916467\n",
      "21300\n",
      "0:00:10.932630\n",
      "21400\n",
      "0:00:13.307255\n",
      "21500\n",
      "0:00:13.549716\n",
      "21600\n",
      "0:00:11.146334\n",
      "21700\n",
      "0:00:10.229397\n",
      "ok\n",
      "21800\n",
      "0:00:11.707149\n",
      "21900\n",
      "0:00:10.224366\n",
      "ok\n",
      "22000\n",
      "0:00:11.989163\n",
      "22100\n",
      "0:00:11.557300\n",
      "22200\n",
      "0:00:10.631624\n",
      "ok\n",
      "22300\n",
      "0:00:11.582670\n",
      "22400\n",
      "0:00:12.222245\n",
      "22500\n",
      "0:00:11.905951\n",
      "22600\n",
      "0:00:11.555761\n",
      "22700\n",
      "0:00:12.891436\n",
      "22800\n",
      "0:00:12.738120\n",
      "22900\n",
      "0:00:15.184081\n",
      "23000\n",
      "0:00:11.530641\n",
      "23100\n",
      "0:00:12.394046\n",
      "23200\n",
      "0:00:11.968518\n",
      "23300\n",
      "0:00:10.108518\n",
      "23400\n",
      "0:00:10.792606\n",
      "23500\n",
      "0:00:12.192139\n",
      "23600\n",
      "0:00:12.645595\n",
      "23700\n",
      "0:00:12.424062\n",
      "23800\n",
      "0:00:11.590883\n",
      "23900\n",
      "0:00:11.839814\n",
      "24000\n",
      "0:00:11.359603\n",
      "24100\n",
      "0:00:11.937774\n",
      "24200\n",
      "0:00:12.455251\n",
      "24300\n",
      "0:00:10.858295\n",
      "24400\n",
      "0:00:11.729801\n",
      "ok\n",
      "24500\n",
      "0:00:11.948712\n",
      "24600\n",
      "0:00:12.707738\n",
      "24700\n",
      "0:00:12.358498\n",
      "24800\n",
      "0:00:11.530500\n",
      "24900\n",
      "0:00:12.951200\n",
      "25000\n",
      "0:00:11.280863\n",
      "25100\n",
      "0:00:12.630300\n",
      "25200\n",
      "0:00:14.737032\n",
      "ok\n",
      "25300\n",
      "0:00:11.970789\n",
      "25400\n",
      "0:00:13.163062\n",
      "25500\n",
      "0:00:11.407582\n",
      "25600\n",
      "0:00:12.030321\n",
      "25700\n",
      "0:00:11.944121\n",
      "25800\n",
      "0:00:11.137102\n",
      "25900\n",
      "0:00:12.160007\n",
      "26000\n",
      "0:00:12.341951\n",
      "26100\n",
      "0:00:12.305704\n",
      "26200\n",
      "0:00:11.863057\n",
      "26300\n",
      "0:00:12.938650\n",
      "26400\n",
      "0:00:14.205203\n",
      "26500\n",
      "0:00:13.372506\n",
      "ok\n",
      "26600\n",
      "0:00:13.311898\n",
      "26700\n",
      "0:00:11.855479\n",
      "ok\n",
      "26800\n",
      "0:00:15.000665\n",
      "26900\n",
      "0:00:13.330462\n",
      "27000\n",
      "0:00:14.856445\n",
      "27100\n",
      "0:00:13.072526\n",
      "27200\n",
      "0:00:13.254861\n",
      "27300\n",
      "0:00:17.073034\n",
      "27400\n",
      "0:00:11.579515\n",
      "27500\n",
      "0:00:12.092386\n",
      "27600\n",
      "0:00:14.064908\n",
      "27700\n",
      "0:00:14.755849\n",
      "27800\n",
      "0:00:15.007103\n",
      "27900\n",
      "0:00:13.855496\n",
      "28000\n",
      "0:00:13.803377\n",
      "28100\n",
      "0:00:09.274398\n",
      "28200\n",
      "0:00:08.898600\n",
      "28300\n",
      "0:00:08.891652\n",
      "ok\n",
      "ok\n",
      "28400\n",
      "0:00:11.386799\n",
      "28500\n",
      "0:00:13.115935\n",
      "ok\n",
      "28600\n",
      "0:00:13.752407\n",
      "28700\n",
      "0:00:13.078437\n",
      "28800\n",
      "0:00:13.192305\n",
      "28900\n",
      "0:00:14.028522\n",
      "29000\n",
      "0:00:15.099589\n",
      "29100\n",
      "0:00:13.071095\n",
      "29200\n",
      "0:00:14.587917\n",
      "ok\n",
      "ok\n",
      "29300\n",
      "0:00:15.680343\n",
      "29400\n",
      "0:00:14.139461\n",
      "29500\n",
      "0:00:14.099258\n",
      "29600\n",
      "0:00:16.146675\n",
      "29700\n",
      "0:00:14.634549\n",
      "29800\n",
      "0:00:14.209463\n",
      "ok\n",
      "29900\n",
      "0:00:15.236626\n",
      "30000\n",
      "0:00:13.894530\n",
      "30100\n",
      "0:00:08.126952\n",
      "30200\n",
      "0:00:16.478586\n",
      "30300\n",
      "0:00:14.243496\n",
      "30400\n",
      "0:00:14.027615\n",
      "ok\n",
      "30500\n",
      "0:00:14.376982\n",
      "30600\n",
      "0:00:13.425979\n",
      "30700\n",
      "0:00:13.846982\n",
      "30800\n",
      "0:00:12.294974\n",
      "30900\n",
      "0:00:14.251711\n",
      "31000\n",
      "0:00:14.161716\n",
      "31100\n",
      "0:00:14.445641\n",
      "31200\n",
      "0:00:16.823151\n",
      "31300\n",
      "0:00:16.106500\n",
      "31400\n",
      "0:00:15.534580\n",
      "31500\n",
      "0:00:15.679560\n",
      "31600\n",
      "0:00:14.542303\n",
      "31700\n",
      "0:00:14.844661\n",
      "ok\n",
      "31800\n",
      "0:00:15.762236\n",
      "31900\n",
      "0:00:14.871450\n",
      "32000\n",
      "0:00:14.168124\n",
      "32100\n",
      "0:00:15.300519\n",
      "32200\n",
      "0:00:14.596118\n",
      "32300\n",
      "0:00:13.851281\n",
      "32400\n",
      "0:00:15.372384\n",
      "32500\n",
      "0:00:15.763341\n",
      "32600\n",
      "0:00:14.871928\n",
      "32700\n",
      "0:00:13.741262\n",
      "32800\n",
      "0:00:14.974280\n",
      "32900\n",
      "0:00:16.596528\n",
      "33000\n",
      "0:00:15.294291\n",
      "33100\n",
      "0:00:14.882028\n",
      "33200\n",
      "0:00:16.972493\n",
      "33300\n",
      "0:00:17.525232\n",
      "33400\n",
      "0:00:15.494049\n",
      "33500\n",
      "0:00:14.075176\n",
      "33600\n",
      "0:00:16.318003\n",
      "33700\n",
      "0:00:17.756660\n",
      "33800\n",
      "0:00:14.999760\n",
      "33900\n",
      "0:00:14.100882\n",
      "34000\n",
      "0:00:14.577971\n",
      "34100\n",
      "0:00:15.052289\n",
      "34200\n",
      "0:00:14.541530\n",
      "34300\n",
      "0:00:16.599939\n",
      "34400\n",
      "0:00:16.312832\n",
      "34500\n",
      "0:00:16.483806\n",
      "34600\n",
      "0:00:14.890140\n",
      "34700\n",
      "0:00:16.427592\n",
      "34800\n",
      "0:00:15.702706\n",
      "34900\n",
      "0:00:14.805824\n",
      "35000\n",
      "0:00:14.557012\n",
      "35100\n",
      "0:00:16.494636\n",
      "35200\n",
      "0:00:17.436445\n",
      "35300\n",
      "0:00:16.944088\n",
      "35400\n",
      "0:00:16.030324\n",
      "35500\n",
      "0:00:15.704410\n",
      "35600\n",
      "0:00:14.994282\n",
      "35700\n",
      "0:00:14.814005\n",
      "35800\n",
      "0:00:15.446207\n",
      "35900\n",
      "0:00:15.813278\n",
      "36000\n",
      "0:00:14.648174\n",
      "36100\n",
      "0:00:16.585558\n",
      "36200\n",
      "0:00:15.088503\n",
      "36300\n",
      "0:00:17.055662\n",
      "36400\n",
      "0:00:16.075325\n",
      "36500\n",
      "0:00:16.132496\n",
      "36600\n",
      "0:00:17.226354\n",
      "36700\n",
      "0:00:17.145021\n",
      "36800\n",
      "0:00:20.285443\n",
      "36900\n",
      "0:00:20.361157\n",
      "37000\n",
      "0:00:16.315192\n",
      "37100\n",
      "0:00:15.992538\n",
      "37200\n",
      "0:00:16.421231\n",
      "37300\n",
      "0:00:16.044144\n",
      "37400\n",
      "0:00:16.707731\n",
      "37500\n",
      "0:00:17.649296\n",
      "37600\n",
      "0:00:16.504025\n",
      "37700\n",
      "0:00:15.809222\n",
      "37800\n",
      "0:00:17.784792\n",
      "37900\n",
      "0:00:19.365550\n",
      "38000\n",
      "0:00:16.598942\n",
      "38100\n",
      "0:00:18.725270\n",
      "38200\n",
      "0:00:15.279552\n",
      "38300\n",
      "0:00:16.129473\n",
      "38400\n",
      "0:00:16.263091\n",
      "38500\n",
      "0:00:18.799915\n",
      "38600\n",
      "0:00:16.371417\n",
      "38700\n",
      "0:00:17.035949\n",
      "38800\n",
      "0:00:15.891428\n",
      "38900\n",
      "0:00:17.808949\n",
      "39000\n",
      "0:00:18.149391\n",
      "39100\n",
      "0:00:20.017026\n",
      "39200\n",
      "0:00:20.471551\n",
      "39300\n",
      "0:00:22.379491\n",
      "39400\n",
      "0:00:20.516272\n",
      "39500\n",
      "0:00:19.373970\n",
      "39600\n",
      "0:00:19.242184\n",
      "39700\n",
      "0:00:20.103008\n",
      "39800\n",
      "0:00:19.070736\n",
      "39900\n",
      "0:00:19.312959\n",
      "40000\n",
      "0:00:22.746021\n",
      "40100\n",
      "0:00:17.026828\n",
      "40200\n",
      "0:00:21.614173\n",
      "40300\n",
      "0:00:18.328547\n",
      "40400\n",
      "0:00:17.609269\n",
      "40500\n",
      "0:00:19.755944\n",
      "40600\n",
      "0:00:20.144171\n",
      "40700\n",
      "0:00:19.479372\n",
      "40800\n",
      "0:00:21.520386\n",
      "40900\n",
      "0:00:18.160060\n",
      "41000\n",
      "0:00:19.901007\n",
      "41100\n",
      "0:00:18.469092\n",
      "41200\n",
      "0:00:20.431810\n",
      "41300\n",
      "0:00:20.066120\n",
      "41400\n",
      "0:00:19.994592\n",
      "41500\n",
      "0:00:19.287654\n",
      "41600\n",
      "0:00:18.415283\n",
      "41700\n",
      "0:00:19.239404\n",
      "41800\n",
      "0:00:18.413405\n",
      "41900\n",
      "0:00:16.989806\n",
      "42000\n",
      "0:00:16.888527\n",
      "42100\n",
      "0:00:20.383684\n",
      "42200\n",
      "0:00:18.381456\n",
      "42300\n",
      "0:00:19.885363\n",
      "42400\n",
      "0:00:18.498427\n",
      "42500\n",
      "0:00:18.989574\n",
      "42600\n",
      "0:00:20.458096\n",
      "42700\n",
      "0:00:19.223352\n",
      "42800\n",
      "0:00:18.568141\n",
      "42900\n",
      "0:00:19.073333\n",
      "43000\n",
      "0:00:19.262925\n",
      "43100\n",
      "0:00:18.770655\n",
      "43200\n",
      "0:00:18.711607\n",
      "43300\n",
      "0:00:18.400269\n",
      "43400\n",
      "0:00:19.057184\n",
      "43500\n",
      "0:00:17.995780\n",
      "43600\n",
      "0:00:12.900410\n",
      "total took: 1:29:10.147863\n"
     ]
    }
   ],
   "source": [
    "new_features_all = np.zeros((0,5))\n",
    "labels_all = np.zeros((0,1))\n",
    "cut_indexes = []\n",
    "# number of closest neighbors to collect recipients from:\n",
    "n = 70\n",
    "\n",
    "\n",
    "#re-arrange train index\n",
    "X_train_info.index = range(X_train_info.shape[0])\n",
    "\n",
    "t_all = datetime.now()\n",
    "t_100 = datetime.now()\n",
    "\n",
    "count = 1\n",
    "query_id = 10040\n",
    "\n",
    "for query_id in X_train_info.index.values:\n",
    "    \n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        print count\n",
    "        print datetime.now()-t_100\n",
    "        t_100 = datetime.now()\n",
    "\n",
    "    # Get info on considered mail\n",
    "    mail = X_train_info['body'][query_id]\n",
    "    mail_tfidf = tfidf.transform([mail])\n",
    "    mail_date = X_train_info['date'][query_id]\n",
    "    ground_truth = X_train_info['recipients'][query_id].split()\n",
    "    sender = X_train_info['sender'][query_id]\n",
    "\n",
    "    X_train_info_sender = X_train_info[(X_train_info.sender == sender) & (X_train_info.date<mail_date)]\n",
    "    if X_train_info_sender.shape[0] == 0:\n",
    "        print 'ok'\n",
    "        continue\n",
    "\n",
    "    # Compute Features For this email\n",
    "    new_features_per_mail, labels_per_mail, dic_of_recipients = generate_features(X_train_info_sender, mail_tfidf, mail_date, ground_truth, sender, n, mail[:10])\n",
    "    # Add to global features\n",
    "    new_features_all = np.concatenate((new_features_all, new_features_per_mail))\n",
    "    labels_all = np.concatenate((labels_all, labels_per_mail))\n",
    "\n",
    "\n",
    "print \"total took:\", datetime.now()-t_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.211284\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "#np.save('../data/new_features_all_normalized_header_recency_70.npy', new_features_all)\n",
    "#np.save('../data/labels_all_normalized_header_recency_70.npy', labels_all)\n",
    "print datetime.now() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_features_all = np.load('../data/new_features_all_normalized_header_recency_70.npy')\n",
    "labels_all = np.ravel(np.load('../data/labels_all_normalized_header_recency_70.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sm = SMOTE(random_state=42)\n",
    "#input_train_duplicate, output_train_duplicate = sm.fit_sample(new_features_all, labels_all)\n",
    "\n",
    "#new_features_all = input_train_duplicate\n",
    "#labels_all = output_train_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:06.191230\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "\n",
    "_classifier = 'LR'\n",
    "\n",
    "if _classifier == 'LinearSVM':\n",
    "    SVM = LinearSVC(dual=False, class_weight='balanced', C=0.001)\n",
    "    if submission == False:\n",
    "        #SVM.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "        SVM.fit(new_features_all, labels_all)\n",
    "    else:\n",
    "        SVM.fit(new_features_all, labels_all)\n",
    "    classifier = SVM\n",
    "elif _classifier == 'LR':\n",
    "# C parameter: smaller values mean bigger regularization\n",
    "#LR_parameters = {'n_estimators' : [5, 10, 20, 50, 100], \n",
    "#                 'dual': [True, False], \n",
    "#                 'penalty' : ['l1', 'l2']}\n",
    "    LR = LogisticRegression(C = 10)\n",
    "    if submission == False:\n",
    "        LR.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        LR.fit(new_features_all, labels_all)\n",
    "    classifier = LR\n",
    "#ABC_parameters = {'n_estimators' : [5, 10, 20, 50, 100], \n",
    "#                'algorithm'=['SAMME.R', 'SAMME']}\n",
    "\n",
    "elif _classifier == 'ABC':\n",
    "    ABC = AdaBoostClassifier()\n",
    "    if submission == False:\n",
    "        ABC.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        ABC.fit(new_features_all, labels_all)\n",
    "    classifier = ABC\n",
    "\n",
    "#RFC_parameters = {'n_estimators' : [10, 50, 100],\n",
    "#                  'class_weight' : [None, 'balanced']}\n",
    "elif _classifier == 'RFC':\n",
    "    RFC = RandomForestClassifier(n_estimators=50, class_weight='balanced')\n",
    "    if submission == False:\n",
    "        RFC.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        RFC.fit(new_features_all, labels_all)\n",
    "    classifier = RFC\n",
    "\n",
    "elif _classifier == 'SVM':\n",
    "    SVM = SVC(kernel='rbf')\n",
    "    if submission == False:\n",
    "        SVM.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "    else:\n",
    "        SVM.fit(new_features_all, labels_all)\n",
    "\n",
    "\n",
    "print datetime.now() - t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0:00:07.552957\n",
      "200\n",
      "0:00:05.853991\n",
      "300\n",
      "0:00:07.824341\n",
      "400\n",
      "0:00:07.198681\n",
      "500\n",
      "0:00:05.991095\n",
      "600\n",
      "0:00:06.419364\n",
      "700\n",
      "0:00:06.730955\n",
      "800\n",
      "0:00:07.070161\n",
      "900\n",
      "0:00:04.950045\n",
      "1000\n",
      "0:00:05.357797\n",
      "1100\n",
      "0:00:06.075724\n",
      "1200\n",
      "0:00:09.615367\n",
      "1300\n",
      "0:00:07.943713\n",
      "1400\n",
      "0:00:06.859174\n",
      "1500\n",
      "0:00:07.392740\n",
      "1600\n",
      "0:00:08.462633\n",
      "1700\n",
      "0:00:07.232874\n",
      "1800\n",
      "0:00:05.585349\n",
      "1900\n",
      "0:00:06.327486\n",
      "2000\n",
      "0:00:05.928502\n",
      "2100\n",
      "0:00:07.157847\n",
      "2200\n",
      "0:00:06.713821\n",
      "2300\n",
      "0:00:07.327939\n",
      "{(100, 'l2'): nan}\n",
      "total took: 0:02:44.162818\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 30\n",
    "\n",
    "#re-arrange train index\n",
    "X_train_info.index = range(X_train_info.shape[0])\n",
    "t_all = datetime.now()\n",
    "t_100 = datetime.now()\n",
    "results = pd.DataFrame(columns=['recipients'])\n",
    "results.index.name = 'mid'\n",
    "all_mean_ap = []\n",
    "all_ground_truth = []\n",
    "all_suggestions = []\n",
    "\n",
    "cross_val_results = {}\n",
    "\n",
    "LR_parameters = {'C' : [0.01, 0.1, 1, 10, 100], \n",
    "                 'penalty' : ['l1', 'l2']}\n",
    "listOLists = [LR_parameters['C'],LR_parameters['penalty']]\n",
    "\n",
    "\n",
    "#for liste in itertools.product(*listOLists):\n",
    "\n",
    "#    C = liste[0]\n",
    "#    penalty = liste[1]\n",
    "##    LR = LogisticRegression(C=C, dual=False, class_weight='balanced',penalty=penalty )\n",
    "#   LR.fit(new_features_all[:cut_indexes[split_date], :], labels_all[:cut_indexes[split_date]])\n",
    "#    classifier = LR\n",
    "    #n_estimators = liste[0]\n",
    "    #algorithm = liste[1]\n",
    "    #ABC = AdaBoostClassifier(n_estimators=n_estimators, algorithm=algorithm)\n",
    "    #ABC.fit(new_features_all, labels_all)\n",
    "\n",
    "    #n_estimators = liste[0]\n",
    "    #class_weight = liste[1]\n",
    "    #RFC = RandomForestClassifier(n_estimators=n_estimators, class_weight=class_weight)\n",
    "    #RFC.fit(new_features_all, labels_all)\n",
    "\n",
    "\n",
    "count=0\n",
    "for query_id in X_test_info.index.values:\n",
    "\n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        print count\n",
    "        print datetime.now()-t_100\n",
    "        t_100 = datetime.now()\n",
    "\n",
    "    mail = X_test_info['body'][query_id]\n",
    "    mail_tfidf = tfidf.transform([mail])\n",
    "    mail_date = X_test_info['date'][query_id]\n",
    "    if submission:\n",
    "        ground_truth = None\n",
    "        query_mid = X_test_info['mid'][query_id]\n",
    "    else:\n",
    "        ground_truth = X_test_info['recipients'][query_id].split()\n",
    "    sender = X_test_info['sender'][query_id]\n",
    "\n",
    "    X_train_info_sender = X_train_info[(X_train_info.sender == sender) & (X_train_info.date<mail_date)]\n",
    "    if X_train_info_sender.shape[0] == 0:\n",
    "        print 'ok'\n",
    "        continue\n",
    "\n",
    "    # Compute Features For this email\n",
    "    new_features_per_mail, labels_per_mail, dic_of_recipients = generate_features(X_train_info_sender, mail_tfidf, mail_date, ground_truth, sender, n, mail[:10])\n",
    "    # Once the features are computed, we can predict the 10 recipients\n",
    "    if _classifier == 'LinearSVM':\n",
    "        order = classifier.decision_function(new_features_per_mail).argsort()[::-1]\n",
    "    else:\n",
    "        order = classifier.predict_proba(new_features_per_mail)[:,1].argsort()[::-1]\n",
    "    recipients = np.array(dic_of_recipients.keys())\n",
    "    suggested_10_recipients = recipients[order][:10]\n",
    "\n",
    "    if submission:\n",
    "        string_recipients = ''\n",
    "        for k in suggested_10_recipients:\n",
    "            string_recipients+=k + ' '\n",
    "        results.loc[query_mid, 'recipients'] = string_recipients\n",
    "    else:\n",
    "\n",
    "        all_suggestions.append(suggested_10_recipients)\n",
    "        all_ground_truth.append(ground_truth)\n",
    "        all_mean_ap.append(mean_ap(suggested_10_recipients, ground_truth))\n",
    "\n",
    "cross_val_results[liste] = np.mean(all_mean_ap)\n",
    "print cross_val_results\n",
    "print \"total took:\", datetime.now()-t_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25197696900982613"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_mean_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv('../submission/learning_basic_LR_with_new_features_30_0-C10-withoutNRF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with io.open('../submission/cross_val_RFC_results_basic_features(same_as_paper).json', 'w', encoding='utf-8') as f:\n",
    "#    f.write(unicode(json.dumps(str(cross_val_results), ensure_ascii=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get NSF and NRF\n",
    "- NSF: number of messages sent by sender to this recipient, divided by all messages sent by sender \n",
    "- NRF: number of messages received from the recipient to the sender, divided by all messages received by sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_to = {}\n",
    "for row in training.iterrows():\n",
    "    sender = row[1]['sender']\n",
    "    sent_to[sender] = {}\n",
    "    for mid in row[1]['mids'].split():\n",
    "        recipients = training_info[training_info.mid == int(mid)]['recipients'].values[0].split()\n",
    "        for recipient in recipients:\n",
    "            if '@' in recipient:\n",
    "                if recipient in sent_to[sender].keys():\n",
    "                    sent_to[sender][recipient] += 1\n",
    "                else:\n",
    "                    sent_to[sender][recipient] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "received_from = {}\n",
    "for sender in sent_to.keys():\n",
    "    for recipient in sent_to[sender].keys():\n",
    "        if recipient not in received_from.keys():\n",
    "            received_from[recipient] = {}\n",
    "        if sender not in received_from[recipient].keys():\n",
    "            received_from[recipient][sender] = sent_to[sender][recipient]\n",
    "        else:\n",
    "            received_from[recipient][sender] += sent_to[sender][recipient]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalization:\n",
    "for sender in sent_to.keys():\n",
    "    norm = sum(sent_to[sender].values())\n",
    "    for recipient in sent_to[sender].keys():\n",
    "        sent_to[sender][recipient] = float(sent_to[sender][recipient])/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalization:\n",
    "for recipient in received_from.keys():\n",
    "    norm = sum(received_from[recipient].values())\n",
    "    for sender in received_from[recipient].keys():\n",
    "        received_from[recipient][sender] = float(received_from[recipient][sender])/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('../data/sent_to.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(unicode(json.dumps(sent_to, ensure_ascii=False)))\n",
    "with io.open('../data/received_from.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(unicode(json.dumps(received_from, ensure_ascii=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with io.open('../data/sent_to.json') as json_data:\n",
    "    sent_to = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "path_to_data = '../data/'\n",
    "\n",
    "##########################\n",
    "# load some of the files #                           \n",
    "##########################\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "\n",
    "################################\n",
    "# create some handy structures #                    \n",
    "################################\n",
    "                            \n",
    "# convert training set to dictionary\n",
    "emails_ids_per_sender = {}\n",
    "for index, series in training.iterrows():\n",
    "    row = series.tolist()\n",
    "    sender = row[0]\n",
    "    ids = row[1:][0].split(' ')\n",
    "    emails_ids_per_sender[sender] = ids\n",
    "\n",
    "# save all unique sender names\n",
    "all_senders = emails_ids_per_sender.keys()\n",
    "\n",
    "# create address book with frequency information for each user\n",
    "address_books = {}\n",
    "i = 0\n",
    "\n",
    "for sender, ids in emails_ids_per_sender.iteritems():\n",
    "    recs_temp = []\n",
    "    for my_id in ids:\n",
    "        recipients = training_info[training_info['mid']==int(my_id)]['recipients'].tolist()\n",
    "        recipients = recipients[0].split(' ')\n",
    "        # keep only legitimate email addresses\n",
    "        recipients = [rec for rec in recipients if '@' in rec]\n",
    "        recs_temp.append(recipients)\n",
    "    # flatten    \n",
    "    recs_temp = [elt for sublist in recs_temp for elt in sublist]\n",
    "    # compute recipient counts\n",
    "    rec_occ = dict(Counter(recs_temp))\n",
    "    # order by frequency\n",
    "    sorted_rec_occ = sorted(rec_occ.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    # save\n",
    "    address_books[sender] = sorted_rec_occ\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print i\n",
    "    i += 1\n",
    "  \n",
    "# save all unique recipient names    \n",
    "all_recs = list(set([elt[0] for sublist in address_books.values() for elt in sublist]))\n",
    "\n",
    "# save all unique user names \n",
    "all_users = []\n",
    "all_users.extend(all_senders)\n",
    "all_users.extend(all_recs)\n",
    "all_users = list(set(all_users))\n",
    "\n",
    "#############\n",
    "# baselines #                           \n",
    "#############\n",
    "\n",
    "# will contain email ids, predictions for random baseline, and predictions for frequency baseline\n",
    "predictions_per_sender = {}\n",
    "\n",
    "# number of recipients to predict\n",
    "k = 10\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    name_ids = row.tolist()\n",
    "    sender = name_ids[0]\n",
    "    # get IDs of the emails for which recipient prediction is needed\n",
    "    ids_predict = name_ids[1].split(' ')\n",
    "    ids_predict = [int(my_id) for my_id in ids_predict]\n",
    "    random_preds = []\n",
    "    freq_preds = []\n",
    "    # select k most frequent recipients for the user\n",
    "    k_most = [elt[0] for elt in address_books[sender][:k]]\n",
    "    for id_predict in ids_predict:\n",
    "        # select k users at random\n",
    "        random_preds.append(random.sample(all_users, k))\n",
    "        # for the frequency baseline, the predictions are always the same\n",
    "        freq_preds.append(k_most)\n",
    "    predictions_per_sender[sender] = [ids_predict,random_preds,freq_preds]\t\n",
    "\n",
    "#################################################\n",
    "# write predictions in proper format for Kaggle #                           \n",
    "#################################################\n",
    "\n",
    "#path_to_results = # fill me!\n",
    "\n",
    "with open(path_to_results + 'predictions_random.txt', 'wb') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for sender, preds in predictions_per_sender.iteritems():\n",
    "        ids = preds[0]\n",
    "        random_preds = preds[1]\n",
    "        for index, my_preds in enumerate(random_preds):\n",
    "            my_file.write(str(ids[index]) + ',' + ' '.join(my_preds) + '\\n')\n",
    "\n",
    "with open(path_to_results + 'predictions_frequency.txt', 'wb') as my_file:\n",
    "    my_file.write('mid,recipients' + '\\n')\n",
    "    for sender, preds in predictions_per_sender.iteritems():\n",
    "        ids = preds[0]\n",
    "        freq_preds = preds[2]\n",
    "        for index, my_preds in enumerate(freq_preds):\n",
    "            my_file.write(str(ids[index]) + ',' + ' '.join(my_preds) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
